## 感知机

感知机perceptron算法最早于1957年由美国学者提出，是神经网络（深度学习）起源的算法。

### 1.1 感知机模型
+ 感知机接收多个输入信号，输出一个信号。输入信号被送往神经元时会被分别乘以固定的权重，神经元计算传送过来的信号的总和，当这个总和超过了某个界限值才会输出1。这个界限值被称为 阈值。
+ 权重越大，对应该权重的信号的重要性就越高。
+ 感知机的局限性在于它只能表示由一条直线分割的空间，弯曲的曲线无法用感知机表示。
+ 单层感知机不能表示异或门
+ 双层感知机表示异或门
+ 单层感知机只能表示线性空间，多层感知机可以表示非线性空间


## 神经网络
### 1.1 激活函数 activation function
式(1)计算加权输入信号和偏置的总和
a = b + w1x1 + w2x2
式(2)用h()激活函数将a转换为输出y
y = h(a)

![](F:\PycharmCode\code_repo\code\dl\figure\激活函数.png)

+ “朴素感知机”是指单层网络，指的是激活函数使用了阶跃函数A 的模型。“多层感知机”是指神经网络，即使用 sigmoid
函数（后述）等平滑的激活函数的多层网络。

#### 1.1.1 sigmoid函数
神经网络中经常使用的一个激活函数是sigmoid函数，用sigmoid函数作为激活函数进行信号的转换，转换后的信号被传送给下一个神经元。
h(x) = 1/(1 + exp(-x))   e = 2.71828...

#### 1.1.2 阶跃函数


#### 1.1.3 ReLU函数
rectified linear unit 函数
h(x) = x (when x > 0) or 0 (when x <= 0)

#### 1.1.4 softmax函数
y = exp(ak)/sum(exp(ak))
ak是输入信号 

### 1.2 前向传播 forward propagation


### 2.1 神经网络的学习
#### 2.1.1 训练集和测试集


#### 2.1.2 损失函数
+ 神经网络以某个指标为线索寻找最优权重参数，神经网络的学习中所用的指标称为 损失函数 loss function
+ 损失函数是表示神经网络性能的 恶劣程度 的指标，即当前的神经网络对监督数据在多大程度上不拟合，多大程度上不一致。
+ 可以做损失函数的函数有很多 均方误差mean squared error;交叉熵误差cross entropy error;

#### 2.1.3 mini-batch学习
+ 使用随机选择的小批量数据的损失函数作为全体训练数据的近似值
+ 


## 梯度法
+ 由全部变量的偏导数汇总而成的向量称为梯度 gradient
+ 鞍点saddle point ： 鞍点是从某个方向上看是极大值，从另一个方向上看则是极小值的点。 
+ 函数的极小值、最小值以及被称为鞍点的地方的梯度为0
+ 在梯度法中，函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断沿着梯度方向前进，逐渐减小函数值的过程就是梯度法 gradient method
+ 严格来说，寻找最小值的梯度法称为梯度下降法 gradient descent method 寻找最大值的梯度法称为梯度上升法 gradient ascent method
+ 


### 3.1 梯度下降
+ 梯度 表示的是各点处的函数值减小最多的方向，因此无法保证梯度所指的方向就是函数的最小值或真正应该前进的方向。
+ 学习率过大或过小都无法得到很好的结果，学习率这样的参数称为 超参数，是一种和神经网络的参数性质不同的参数，这种参数需要人工设定。
+ 神经网络的学习也需要梯度，这里的梯度是指 损失函数关于权重参数的梯度。
+ 

### 3.2 学习算法的实现
神经网络的学习步骤：（其实就是 随机梯度下降法 stochastic gradient descent）
1，mini-batch
从训练数据中随机选出一部分数据mini-batch，目标是减小mini-batch的损失函数的最小值
2.计算梯度
为了减小mini-batch的损失函数的值，需要求出各个权重参数的梯度，梯度表示损失函数的值减小最多的方向
3.更新参数
将权重参数沿梯度方向进行微小更新
4.重复
重复步骤1 2 3


+ epoch 是一个单位，一个epoch表示学习中所有训练数据均被使用过一次时的更新次数。
+ 


## 误差反向传播法计算梯度
### 4.1 局部计算
+ 计算图 无论全局的计算有多复杂，各个步骤要做的就是对象节点的局部计算。通过传递局部计算的结果，可以获得全局的复杂计算的结果。
+ 无论全局是多么复杂的计算都可以通过局部计算使各个节点致力于简单的计算，从而简化问题。另外，计算图可以将中间的计算结果全部保存起来。
+ 计算图可以通过反向传播高效计算导数


### 4.2 链式法则 chain rule
+ 链式法则是关于复合函数的导数的性质：如果某个函数由复合函数表示，则该复合函数的导数可以用构成复合函数的各个函数的导数的乘积表示。
+ 



## 参数优化
+ 神经网络学习的目的是为了找到使损失函数的值尽可能小的参数。即最优参数，这个过程就是最优化optimization


### 5.1 stochastic gradient descent 随机梯度下降
+ SGD的缺点是：如果函数的形状非均向anisotropic，搜索的路径就会很低效
+ 低效的原因是 梯度的方向并没有指向最小值的方向

### 5.2 Momentum 
+ 添加了 速度v变量修改移动规则

### 5.3 AdaGrad

+ AdaGrad会记录过去所有梯度的平方和，因此，学习越深入更新的幅度就越小。
+ 为了改善这个问题，可以使用RMSProp方法，这个方法会逐渐遗忘过去的梯度，在做加法运算时将新梯度的信息更多地反映出来，称为“指数移动平均”


### 5.4 Adam
+ 融合了Momentum和AdaGrad两种方法
+ 

![](F:\PycharmCode\code_repo\code\dl\figure\参数更新方法.jpg)


##
### 6.1 权重的初始值
+ 要避免 权重均一化，更严格来说，是为了瓦解权重的对称结构，所以必须随机生成初始值。
+ 在一般的深度学习框架如Caffe中，Xavier初始值已被作为标准使用，通过在设定权重初始值时赋予xavier参数，就可以使用Xavier初始值。
+ 

### 6.2 Batch Normalization
+ batch norm 的思路是调整各层的激活值分布使其拥有适当的广度，为此，要向神经网络中插入对数据分布进行正规化的层
+ 其实就是以 进行学习时的mini-batch为单位，按mini-batch进行正规化


### 6.3 正则化
#### 6.3.1 权值衰减
+ 在损失函数上加上权重的平方范数 L2范数


#### 6.3.2 Dropout
+ 一种在学习过程中随机删除神经元的方法。
+ 训练时，每传递一次数据，就会随机选择要删除的神经元，然后在测试时，虽然会传递所有的神经元信号，但是对于各个神经元的输出，要乘上训练时的删除比例后再输出。
+ 

#### 6.3.3 超参数hyper-parameter的验证
+ 不能使用测试数据评估超参数的性能，避免发生过拟合
+ 调整超参数时，必须使用超参数专用的确认数据，这个数据一般被称为 验证数据validation data
+ 训练数据用于参数（权重和偏置）的学习，验证数据用于超参数的性
能评估。
+ 

#### 6.3.4 超参数的最优化
+ 进行超参数的最优化时，逐渐缩小超参数的 好值 的存在范围非常重要。（一开始大致设定一个范围，从这个范围中随机选出一个超参数，采样的方法，用这个采样到的值进行识别精度的评估，然后重复根据识别精度的结果缩小超参数的 好值 的范围）
+ 在超参数的最优化中，减少学习的epoch，缩短一次评估所需的时间是个加快搜索的好办法。
+ 

超参数的最优化步骤：
1.设定超参数的范围
2.从设定的超参数范围中随机采样
3.使用步骤2中采样得到的超参数的值进行学习，通过验证数据评估识别精度(但是要将epoch设置得很小)
4.重复步骤2和3 根据识别精度的结果缩小超参数的范围







